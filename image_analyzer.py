import base64
import json
from io import BytesIO
from PIL import Image
import ollama
from config import Config, PLATFORM_TEMPLATES

class ImageAnalyzer:
    def __init__(self):
        self.config = Config()
        self.model = self.config.OLLAMA_MODEL
    
    def compress_image(self, image_path, max_size=(1536, 1536), quality=90):
        """å‹ç¼©å›¾ç‰‡ä»¥å‡å°‘æ¨¡å‹å¤„ç†æ—¶é—´å’Œå†…å­˜å ç”¨ï¼Œé’ˆå¯¹ç›¸æœºå¤§å›¾ç‰‡ä¼˜åŒ–"""
        with Image.open(image_path) as img:
            # è·å–åŸå§‹å°ºå¯¸
            original_size = img.size
            
            # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœæ˜¯RGBAæˆ–å…¶ä»–æ ¼å¼ï¼‰
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # å¯¹äºéå¸¸å¤§çš„å›¾ç‰‡ï¼Œå…ˆè¿›è¡Œé¢„å¤„ç†
            if max(original_size) > 6000:  # è¶…è¿‡6000åƒç´ çš„å¤§å›¾
                # å…ˆç¼©æ”¾åˆ°åˆç†å°ºå¯¸
                pre_scale = (3000, 3000)
                img.thumbnail(pre_scale, Image.Resampling.LANCZOS)
            
            # æŒ‰æ¯”ä¾‹ç¼©æ”¾åˆ°ç›®æ ‡å°ºå¯¸
            img.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # ä¿å­˜åˆ°å†…å­˜ï¼Œæé«˜è´¨é‡ä»¥ä¿æŒç»†èŠ‚
            buffer = BytesIO()
            img.save(buffer, format='JPEG', quality=quality, optimize=True)
            buffer.seek(0)
            
            return buffer.getvalue(), original_size, img.size
    
    def generate_platform_prompt(self, platform='general', language='zh'):
        """æ ¹æ®ä¸åŒå¹³å°å’Œè¯­è¨€ç”Ÿæˆä¼˜åŒ–çš„æç¤ºè¯"""
        
        if language == 'zh':
            # æ ¹æ®å¹³å°è°ƒæ•´åˆ†ç±»é€‰é¡¹
            if platform == 'tuchong' and platform in PLATFORM_TEMPLATES:
                categories = PLATFORM_TEMPLATES[platform].get('categories', [])
                category_options = 'ã€'.join(categories)
                base_prompt = f"""è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œå¹¶æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆè¯·ç”¨ä¸­æ–‡å›ç­”ï¼‰ï¼š

{{
    "image_type": "å›¾ç‰‡åˆ†ç±»ï¼Œå¿…é¡»ä»ä»¥ä¸‹é€‰é¡¹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š{category_options}ã€‚å¦‚æœè¯†åˆ«ä¸å‡ºå…·ä½“åˆ†ç±»ï¼Œè¯·é€‰æ‹©'å…¶ä»–'",
    "description": "å›¾ç‰‡è¯´æ˜ï¼Œç®€æ´æ˜äº†åœ°æè¿°å›¾ç‰‡çš„ä¸»è¦å†…å®¹å’Œç‰¹ç‚¹",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2", "å…³é”®è¯3", "å…³é”®è¯4", "å…³é”®è¯5", "å…³é”®è¯6", "å…³é”®è¯7", "..."]
}}

é‡è¦è¦æ±‚ï¼š
1. image_typeå­—æ®µå¿…é¡»ä¸¥æ ¼ä»ç»™å®šçš„12ä¸ªåˆ†ç±»é€‰é¡¹ä¸­é€‰æ‹©ï¼Œä¸èƒ½ä½¿ç”¨å…¶ä»–åˆ†ç±»
2. å¦‚æœæ— æ³•ç¡®å®šå…·ä½“åˆ†ç±»ï¼Œè¯·é€‰æ‹©"å…¶ä»–"
3. keywordså­—æ®µå¿…é¡»åŒ…å«è‡³å°‘5ä¸ªä»¥ä¸Šçš„å…³é”®è¯ï¼Œç”¨äºæè¿°å›¾ç‰‡å†…å®¹ã€é£æ ¼ã€è‰²å½©ã€æƒ…æ„Ÿç­‰
4. æ‰€æœ‰å†…å®¹éƒ½ç”¨ä¸­æ–‡è¾“å‡º
5. è¯·æ ¹æ®å›¾ç‰‡å†…å®¹ä»”ç»†é€‰æ‹©æœ€åˆé€‚çš„åˆ†ç±»"""
            else:
                base_prompt = """è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œå¹¶æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼ˆè¯·ç”¨ä¸­æ–‡å›ç­”ï¼‰ï¼š

{
    "image_type": "å›¾ç‰‡ç±»å‹ï¼ˆé£æ™¯/äººç‰©/åŠ¨ç‰©/å»ºç­‘/é£Ÿç‰©/äº§å“/æŠ½è±¡/å…¶ä»–ï¼‰",
    "main_subject": "ä¸»è¦å†…å®¹çš„ç®€æ´æè¿°",
    "detailed_description": "è¯¦ç»†æè¿°å›¾ç‰‡çš„æ„å›¾ã€è‰²å½©ã€å…‰çº¿ã€æ°›å›´ç­‰",
    "keywords_cn": ["ä¸­æ–‡å…³é”®è¯1", "ä¸­æ–‡å…³é”®è¯2", "..."],
    "keywords_en": ["English keyword1", "English keyword2", "..."],
    "mood": "æƒ…æ„Ÿè‰²è°ƒï¼ˆç§¯æ/ä¸­æ€§/æ¶ˆæ/ç¥ç§˜/æ¸©æš–/å†·é™ç­‰ï¼‰",
    "color_palette": ["ä¸»è¦é¢œè‰²1", "ä¸»è¦é¢œè‰²2", "..."],
    "composition": "æ„å›¾æè¿°ï¼ˆä¸‰åˆ†æ³•/å¯¹ç§°/å¼•å¯¼çº¿ç­‰ï¼‰",
    "lighting": "å…‰çº¿æè¿°ï¼ˆè‡ªç„¶å…‰/äººå·¥å…‰/é€†å…‰/ä¾§å…‰ç­‰ï¼‰",
    "commercial_use": "å•†ä¸šç”¨é€”å»ºè®®",
    "target_audience": "ç›®æ ‡å—ä¼—",
    "seasonal": "å­£èŠ‚æ€§ï¼ˆå¦‚é€‚ç”¨ï¼‰",
    "location_type": "åœºæ™¯ç±»å‹ï¼ˆå®¤å†…/å®¤å¤–/å·¥ä½œå®¤ç­‰ï¼‰"
}

é‡è¦ï¼šè¯·ç¡®ä¿æ‰€æœ‰æè¿°æ€§æ–‡å­—éƒ½ä½¿ç”¨ä¸­æ–‡ï¼Œå…³é”®è¯éƒ¨åˆ†æä¾›ä¸­è‹±æ–‡ä¸¤ä¸ªç‰ˆæœ¬ã€‚"""
        else:
            # æ ¹æ®å¹³å°è°ƒæ•´åˆ†ç±»é€‰é¡¹
            if platform == 'tuchong' and platform in PLATFORM_TEMPLATES:
                categories = PLATFORM_TEMPLATES[platform].get('categories', [])
                category_options = ', '.join(categories)
                base_prompt = f"""Please analyze this image in detail and output in the following JSON format:

{{
    "image_type": "Image category, must choose one from: {category_options}. If cannot identify specific category, choose 'Other'",
    "description": "Image description, concisely describe the main content and characteristics of the image",
    "keywords": ["keyword1", "keyword2", "keyword3", "keyword4", "keyword5", "keyword6", "keyword7", "..."]
}}

Important requirements:
1. The image_type field must strictly choose from the given 12 category options, no other categories allowed
2. If unable to determine specific category, choose "Other"
3. The keywords field must contain at least 5 or more keywords describing image content, style, colors, emotions, etc.
4. All content should be in Chinese
5. Please carefully select the most appropriate category based on the image content"""
            else:
                base_prompt = """Please analyze this image in detail and output in the following JSON format (please answer in English):

{
    "image_type": "Image type (landscape/portrait/animal/architecture/food/product/abstract/other)",
    "main_subject": "Brief description of main content",
    "detailed_description": "Detailed description of composition, colors, lighting, atmosphere, etc.",
    "keywords_cn": ["Chinese keyword1", "Chinese keyword2", "..."],
    "keywords_en": ["English keyword1", "English keyword2", "..."],
    "mood": "Emotional tone (positive/neutral/negative/mysterious/warm/calm, etc.)",
    "color_palette": ["Main color1", "Main color2", "..."],
    "composition": "Composition description (rule of thirds/symmetry/leading lines, etc.)",
    "lighting": "Lighting description (natural light/artificial light/backlight/side light, etc.)",
    "commercial_use": "Commercial use suggestions",
    "target_audience": "Target audience",
    "seasonal": "Seasonality (if applicable)",
    "location_type": "Scene type (indoor/outdoor/studio, etc.)"
}

Important: Please ensure all descriptive text is in English, and provide both Chinese and English versions for keywords."""

        if platform in PLATFORM_TEMPLATES:
            template = PLATFORM_TEMPLATES[platform]
            if language == 'zh':
                platform_prompt = f"{base_prompt}\n\nç‰¹åˆ«è¦æ±‚ï¼š{template['prompt_suffix']}"
                platform_prompt += f"\nå…³é”®è¯æ•°é‡é™åˆ¶ï¼š{template['max_keywords']}ä¸ª"
            else:
                platform_prompt = f"{base_prompt}\n\nSpecial requirements: {template['prompt_suffix']}"
                platform_prompt += f"\nKeyword limit: {template['max_keywords']} keywords"
            return platform_prompt
        
        return base_prompt
    
    def check_and_download_model(self, model_name):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å°è¯•ä¸‹è½½"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²å®‰è£…
            models = ollama.list()
            available_models = [model['name'] for model in models['models']]
            
            if model_name not in available_models:
                print(f"æ¨¡å‹ {model_name} æœªæ‰¾åˆ°ï¼Œæ­£åœ¨ä¸‹è½½...")
                # å°è¯•ä¸‹è½½æ¨¡å‹
                import subprocess
                result = subprocess.run(
                    ['ollama', 'pull', model_name],
                    capture_output=True,
                    text=True,
                    timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
                )
                
                if result.returncode == 0:
                    print(f"æ¨¡å‹ {model_name} ä¸‹è½½æˆåŠŸ")
                    return True
                else:
                    print(f"æ¨¡å‹ {model_name} ä¸‹è½½å¤±è´¥: {result.stderr}")
                    return False
            
            return True
            
        except Exception as e:
            print(f"æ£€æŸ¥/ä¸‹è½½æ¨¡å‹æ—¶å‡ºé”™: {str(e)}")
            return False

    def analyze_image(self, image_path, platform='general', model=None, language='zh'):
        """ä½¿ç”¨æŒ‡å®šæ¨¡å‹åˆ†æå›¾ç‰‡"""
        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
        if model is None:
            model = self.model
        
        # æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if not self.check_and_download_model(model):
            return {
                'error': f"æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥OllamaæœåŠ¡æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹",
                'image_info': {
                    'platform': platform
                }
            }
        
        try:
            # å‹ç¼©å›¾ç‰‡
            compressed_image, original_size, compressed_size = self.compress_image(image_path)
            
            # è½¬æ¢ä¸ºbase64
            image_b64 = base64.b64encode(compressed_image).decode('utf-8')
            
            # ç”Ÿæˆå¹³å°å’Œè¯­è¨€ç‰¹å®šçš„æç¤ºè¯
            prompt = self.generate_platform_prompt(platform, language)
            
            # è°ƒç”¨Ollama API
            response = ollama.chat(
                model=model,
                messages=[{
                    'role': 'user',
                    'content': prompt,
                    'images': [image_b64]
                }],
                options={
                    'temperature': 0.7,
                    'top_p': 0.9,
                    'num_predict': 1000
                }
            )
            
            # å°è¯•è§£æJSONå“åº”
            content = response['message']['content']
            
            # æå–JSONéƒ¨åˆ†
            try:
                # æŸ¥æ‰¾JSONå¼€å§‹å’Œç»“æŸä½ç½®
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_str = content[json_start:json_end]
                    analysis_data = json.loads(json_str)
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                    analysis_data = {"raw_response": content}
                
            except json.JSONDecodeError:
                # JSONè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”
                analysis_data = {"raw_response": content}
            
            # æ·»åŠ å›¾ç‰‡å…ƒä¿¡æ¯
            analysis_data['image_info'] = {
                'original_size': original_size,
                'compressed_size': compressed_size,
                'platform': platform
            }
            
            return analysis_data
            
        except Exception as e:
            return {
                'error': f"åˆ†æå¤±è´¥: {str(e)}",
                'image_info': {
                    'platform': platform
                }
            }
    
    def format_for_platform(self, analysis_data, platform='general', language='zh'):
        """æ ¹æ®å¹³å°è¦æ±‚æ ¼å¼åŒ–è¾“å‡º"""
        if 'error' in analysis_data:
            error_text = "åˆ†æå¤±è´¥ï¼š" if language == 'zh' else "Analysis failed: "
            return f"{error_text}{analysis_data.get('error', 'æœªçŸ¥é”™è¯¯')}"
        
        if platform not in PLATFORM_TEMPLATES:
            return self._format_general(analysis_data, language)
        
        template = PLATFORM_TEMPLATES[platform]
        
        if platform == 'tuchong':
            return self._format_tuchong(analysis_data, template, language)
        elif platform == 'shutterstock':
            return self._format_shutterstock(analysis_data, template, language)
        elif platform == 'getty':
            return self._format_getty(analysis_data, template, language)
        elif platform == 'adobe_stock':
            return self._format_adobe_stock(analysis_data, template, language)
        else:
            return self._format_general(analysis_data, language)
    
    def _format_general(self, data, language='zh'):
        """é€šç”¨æ ¼å¼åŒ–"""
        if 'raw_response' in data:
            prefix = "AIåˆ†æç»“æœï¼š" if language == 'zh' else "AI Analysis Result:"
            return f"{prefix}\n{data['raw_response']}"
        
        result = []
        
        if language == 'zh':
            result.append(f"ğŸ“· å›¾ç‰‡ç±»å‹ï¼š{data.get('image_type', 'æœªçŸ¥')}")
            result.append(f"ğŸ¯ ä¸»è¦å†…å®¹ï¼š{data.get('main_subject', 'æœªæè¿°')}")
            result.append(f"ğŸ“ è¯¦ç»†æè¿°ï¼š{data.get('detailed_description', 'æœªæè¿°')}")
            
            if data.get('keywords_cn'):
                result.append(f"ğŸ·ï¸ ä¸­æ–‡å…³é”®è¯ï¼š{', '.join(data['keywords_cn'])}")
            
            if data.get('keywords_en'):
                result.append(f"ğŸ·ï¸ è‹±æ–‡å…³é”®è¯ï¼š{', '.join(data['keywords_en'])}")
            
            result.append(f"ğŸ˜Š æƒ…æ„Ÿè‰²è°ƒï¼š{data.get('mood', 'æœªçŸ¥')}")
            result.append(f"ğŸ¨ è‰²å½©æ­é…ï¼š{', '.join(data.get('color_palette', []))}")
            result.append(f"ğŸ“ æ„å›¾æ–¹å¼ï¼š{data.get('composition', 'æœªæè¿°')}")
            result.append(f"ğŸ’¡ å…‰çº¿æ•ˆæœï¼š{data.get('lighting', 'æœªæè¿°')}")
            result.append(f"ğŸ’¼ å•†ä¸šç”¨é€”ï¼š{data.get('commercial_use', 'æœªå»ºè®®')}")
        else:
            result.append(f"ğŸ“· Image Type: {data.get('image_type', 'Unknown')}")
            result.append(f"ğŸ¯ Main Subject: {data.get('main_subject', 'Not described')}")
            result.append(f"ğŸ“ Detailed Description: {data.get('detailed_description', 'Not described')}")
            
            if data.get('keywords_en'):
                result.append(f"ğŸ·ï¸ English Keywords: {', '.join(data['keywords_en'])}")
            
            if data.get('keywords_cn'):
                result.append(f"ğŸ·ï¸ Chinese Keywords: {', '.join(data['keywords_cn'])}")
            
            result.append(f"ğŸ˜Š Mood: {data.get('mood', 'Unknown')}")
            result.append(f"ğŸ¨ Color Palette: {', '.join(data.get('color_palette', []))}")
            result.append(f"ğŸ“ Composition: {data.get('composition', 'Not described')}")
            result.append(f"ğŸ’¡ Lighting: {data.get('lighting', 'Not described')}")
            result.append(f"ğŸ’¼ Commercial Use: {data.get('commercial_use', 'Not suggested')}")
        
        return '\n'.join(result)
    
    def _format_tuchong(self, data, template, language='zh'):
        """å›¾è™«ç½‘æ ¼å¼åŒ– - åªä¿ç•™å›¾ç‰‡åˆ†ç±»ã€å›¾ç‰‡è¯´æ˜ã€å›¾ç‰‡å…³é”®å­—"""
        result = []
        if language == 'zh':
            # å›¾ç‰‡åˆ†ç±»
            image_type = data.get('image_type', 'å…¶ä»–')
            result.append(f"å›¾ç‰‡åˆ†ç±»ï¼š{image_type}")
            
            # å›¾ç‰‡è¯´æ˜
            description = data.get('description', data.get('detailed_description', data.get('main_subject', '')))
            if description:
                result.append(f"å›¾ç‰‡è¯´æ˜ï¼š{description}")
            
            # å›¾ç‰‡å…³é”®å­— - è‡³å°‘5ä¸ªä»¥ä¸Š
            keywords = data.get('keywords', data.get('keywords_cn', []))
            if not keywords:
                # å¦‚æœæ²¡æœ‰keywordså­—æ®µï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
                keywords = data.get('keywords_en', [])
            
            if keywords:
                # ç¡®ä¿è‡³å°‘æœ‰5ä¸ªå…³é”®è¯
                if len(keywords) < 5:
                    # å¦‚æœå…³é”®è¯ä¸è¶³5ä¸ªï¼Œå¯ä»¥ä»å…¶ä»–å­—æ®µè¡¥å……
                    additional_keywords = []
                    if data.get('mood'):
                        additional_keywords.append(data['mood'])
                    if data.get('color_palette'):
                        additional_keywords.extend(data['color_palette'][:2])  # æœ€å¤šå–2ä¸ªé¢œè‰²
                    keywords.extend(additional_keywords)
                
                # é™åˆ¶å…³é”®è¯æ•°é‡ä¸è¶…è¿‡æ¨¡æ¿é™åˆ¶
                keywords = keywords[:template['max_keywords']]
                result.append(f"å›¾ç‰‡å…³é”®å­—ï¼š{', '.join(keywords)}")
            else:
                result.append("å›¾ç‰‡å…³é”®å­—ï¼šæš‚æ— ")
                
        else:
            # Image Category
            image_type = data.get('image_type', 'Other')
            result.append(f"Image Category: {image_type}")
            
            # Image Description
            description = data.get('description', data.get('detailed_description', data.get('main_subject', '')))
            if description:
                result.append(f"Image Description: {description}")
            
            # Image Keywords - at least 5
            keywords = data.get('keywords', data.get('keywords_en', []))
            if not keywords:
                keywords = data.get('keywords_cn', [])
            
            if keywords:
                # Ensure at least 5 keywords
                if len(keywords) < 5:
                    additional_keywords = []
                    if data.get('mood'):
                        additional_keywords.append(data['mood'])
                    if data.get('color_palette'):
                        additional_keywords.extend(data['color_palette'][:2])
                    keywords.extend(additional_keywords)
                
                keywords = keywords[:template['max_keywords']]
                result.append(f"Image Keywords: {', '.join(keywords)}")
            else:
                result.append("Image Keywords: None")
        
        return '\n'.join(result)
    
    def _format_shutterstock(self, data, template, language='zh'):
        """Shutterstockæ ¼å¼åŒ–"""
        result = []
        if language == 'zh':
            result.append("ğŸ“¸ Shutterstockä¾›ç¨¿æ ¼å¼")
            result.append("=" * 35)
            result.append(f"æ ‡é¢˜ï¼š{data.get('main_subject', 'ä¸“ä¸šåº“å­˜ç…§ç‰‡')}")
            result.append(f"æè¿°ï¼š{data.get('detailed_description', '')}")
            
            keywords = data.get('keywords_en', [])
            if keywords:
                keywords = keywords[:template['max_keywords']]
                result.append(f"å…³é”®è¯ï¼š{', '.join(keywords)}")
            
            result.append(f"ç±»åˆ«ï¼š{data.get('image_type', 'é€šç”¨')}")
            result.append(f"å•†ä¸šç”¨é€”ï¼š{data.get('commercial_use', 'æ˜¯')}")
        else:
            result.append("ğŸ“¸ Shutterstock Format")
            result.append("=" * 35)
            result.append(f"Title: {data.get('main_subject', 'Professional Stock Photo')}")
            result.append(f"Description: {data.get('detailed_description', '')}")
            
            keywords = data.get('keywords_en', [])
            if keywords:
                keywords = keywords[:template['max_keywords']]
                result.append(f"Keywords: {', '.join(keywords)}")
            
            result.append(f"Category: {data.get('image_type', 'General')}")
            result.append(f"Commercial Use: {data.get('commercial_use', 'Yes')}")
        
        return '\n'.join(result)
    
    def _format_getty(self, data, template, language='zh'):
        """Getty Imagesæ ¼å¼åŒ–"""
        result = []
        if language == 'zh':
            result.append("ğŸ›ï¸ Getty Imagesä¾›ç¨¿æ ¼å¼")
            result.append("=" * 35)
            result.append(f"æ ‡é¢˜ï¼š{data.get('main_subject', '')}")
            result.append(f"è¯´æ˜ï¼š{data.get('detailed_description', '')}")
            
            keywords = data.get('keywords_en', [])
            if keywords:
                keywords = keywords[:template['max_keywords']]
                result.append(f"å…³é”®è¯ï¼š{', '.join(keywords)}")
            
            result.append(f"ç¼–è¾‘ç”¨é€”ï¼š{data.get('target_audience', 'å¤§ä¼—')}")
        else:
            result.append("ğŸ›ï¸ Getty Images Format")
            result.append("=" * 35)
            result.append(f"Headline: {data.get('main_subject', '')}")
            result.append(f"Caption: {data.get('detailed_description', '')}")
            
            keywords = data.get('keywords_en', [])
            if keywords:
                keywords = keywords[:template['max_keywords']]
                result.append(f"Keywords: {', '.join(keywords)}")
            
            result.append(f"Editorial Use: {data.get('target_audience', 'General Public')}")
        
        return '\n'.join(result)
    
    def _format_adobe_stock(self, data, template, language='zh'):
        """Adobe Stockæ ¼å¼åŒ–"""
        result = []
        if language == 'zh':
            result.append("ğŸ¨ Adobe Stockä¾›ç¨¿æ ¼å¼")
            result.append("=" * 35)
            result.append(f"æ ‡é¢˜ï¼š{data.get('main_subject', '')}")
            result.append(f"æè¿°ï¼š{data.get('detailed_description', '')}")
            
            keywords = data.get('keywords_en', [])
            if keywords:
                keywords = keywords[:template['max_keywords']]
                result.append(f"å…³é”®è¯ï¼š{', '.join(keywords)}")
            
            result.append(f"ç±»åˆ«ï¼š{data.get('image_type', '')}")
            result.append(f"æƒ…æ„Ÿï¼š{data.get('mood', '')}")
        else:
            result.append("ğŸ¨ Adobe Stock Format")
            result.append("=" * 35)
            result.append(f"Title: {data.get('main_subject', '')}")
            result.append(f"Description: {data.get('detailed_description', '')}")
            
            keywords = data.get('keywords_en', [])
            if keywords:
                keywords = keywords[:template['max_keywords']]
                result.append(f"Keywords: {', '.join(keywords)}")
            
            result.append(f"Category: {data.get('image_type', '')}")
            result.append(f"Mood: {data.get('mood', '')}")
        
        return '\n'.join(result)